{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandarin dictionnary\n",
    "\n",
    "\n",
    "On going \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "from docx import Document\n",
    "\n",
    "import jieba as ji\n",
    "import jieba.analyse as ja\n",
    "\n",
    "__dict_path = '/Users/macbuse/jieba-master/extra_dict/'\n",
    "ja.set_stop_words(__dict_path + \"stop_words.txt\")\n",
    "ja.set_idf_path(__dict_path + \"../extra_dict/idf.txt.big\");\n",
    "\n",
    "__dict_path = '/Users/macbuse/jieba-master/extra_dict'\n",
    "\n",
    "ep = re.compile('a|e|i|o|u')\n",
    "\n",
    "#I took the html stuff and now it's a string in this module\n",
    "from html_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWords(dict):\n",
    "    \n",
    "    def __init__(self,  \n",
    "                 src_pkl='words.pkl',\n",
    "                 tooltip='test'):\n",
    "        self.ordered_keys = []\n",
    "        self.src = src_pkl\n",
    "        tail = ' data-placement=\"top\" title=\"%s\">%s </a>'\n",
    "        self.wrapper = '<a class=\"%s\" href=\"#\" data-toggle=\"tooltip\"'%tooltip + tail \n",
    "        \n",
    "    \n",
    "    def tidy(self):\n",
    "        LL = self.keys()\n",
    "        LL.sort()\n",
    "        self.ordered_keys = LL\n",
    "        \n",
    "    def show_all(self):\n",
    "        self.tidy()\n",
    "        for x in self.ordered_keys:\n",
    "            print self.show(x)\n",
    "            \n",
    "    def look_up(self, other):\n",
    "        return [self.show(x) for x in other if x in self]\n",
    "    \n",
    "    def wrap(self, entity):\n",
    "        \n",
    "        if entity in self and self[entity]: \n",
    "            payload = '%s : %s' %self[entity]\n",
    "            if isinstance(payload, str):\n",
    "                payload = unicode(payload,'utf8')\n",
    "            return self.wrapper%(payload, entity)\n",
    "        else:\n",
    "            return entity\n",
    "         \n",
    "    def missing(self, other):\n",
    "        return [x for x in other if x not in self]\n",
    "    \n",
    "    def load(self):\n",
    "        tt = pickle.load(file(self.src,'r') ) \n",
    "        self.update(tt)\n",
    "        \n",
    "    def dump(self):\n",
    "        #not nice but we want to get it back one day\n",
    "        #even if we have modified the class definition so...\n",
    "        copy = {}\n",
    "        copy.update(self)\n",
    "        with file(self.src, 'wb') as fp:\n",
    "            pickle.dump(copy, fp)\n",
    "         \n",
    "    def show(self, key):\n",
    "        if not self[key]: return key + ' None'\n",
    "        payload = ' %s : %s' %self[key]\n",
    "        if isinstance(payload, str):\n",
    "            payload = unicode(' %s : %s' %self[key], 'utf8')\n",
    "        return key + payload\n",
    "    \n",
    "def txt2web(paras=['',''],\n",
    "            my_words=[MyWords()],\n",
    "            fn='test_tool.html'):\n",
    "    \n",
    "    '''mark up a text with tool tips\n",
    "    from a list of  MyWord objects'''\n",
    "    import html_code\n",
    "    my_html = []\n",
    "    for para in paras[:]:\n",
    "        txt = [x[0] for x in ji.tokenize(para)]\n",
    "        for word_list in my_words:\n",
    "            #wrap() returns the string \n",
    "            #if it has already been  treated\n",
    "            txt = [word_list.wrap(w) for w in txt]              \n",
    "        my_html.append(txt)\n",
    "\n",
    "    my_html = [ '<p>%s</p>\\n'%' '.join( para) for para in html]\n",
    "    my_html = ''.join( my_html)\n",
    "    my_html= html_wrapper%my_html\n",
    "    \n",
    "    with codecs.open( fn, 'w', encoding='utf8') as ff:\n",
    "        ff.write( my_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2web(paras, my_words=[wiki_words,tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = MyWords(src_pkl='m2e_word_pinyin_meaning.pkl',\n",
    "             tooltip='test1')\n",
    "tt.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = Document('/Users/macbuse/Downloads/ZHU_TRANSLATIONS/holler_CN.docx')\n",
    "doc = Document('/Users/macbuse/Downloads/ZHU_TRANSLATIONS/汪化 灵魂深处的生长 .docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汪化 灵魂深处的生长 Growth from depth of the soul\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in doc.paragraphs[:1]:\n",
    "    print x.text\n",
    "    print '-'*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在\t早期\t的\t艺术作品\t中\t，\t你\t显示\t对\t数学\t"
     ]
    }
   ],
   "source": [
    "result = ji.tokenize(doc.paragraphs[2].text)\n",
    "for tk in list(result)[:10]:\n",
    "    print u\"%s\\t\" % tk[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content = '\\n'.join( [para.text for para in doc.paragraphs])\n",
    "\n",
    "def get_words(txt):\n",
    "    topK = 100\n",
    "    tags = ja.extract_tags(txt, topK=topK)\n",
    "    # if it is a number or english then kill it\n",
    "    p_kill = re.compile('(\\d+)|(a|e|i|o|u)')\n",
    "    #always convert to lower\n",
    "    return [x for x in tags if not p_kill.search(x.lower()) ]\n",
    "\n",
    "top100 = get_words(' '.join(contents2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张帆\\ 绘画\\ 布面\\ 劳作\\ 急就章\\ 自叙\\ 属于\\ 成为\\ 山林\\ 现在\\ 逻辑\\ 危险\\ 视为\\ 奇观\\ 气息\\ 基座\\ 形式主义\\ 水图\\ 抽象画\\ 一张\\ 书写\\ 丙烯\\ 质感\n"
     ]
    }
   ],
   "source": [
    "mm = wiki_words.missing(top100) \n",
    "print '\\ '.join( tt.missing(mm) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一种 yī zhǒng : one kind of, one type of\n",
      "这个 zhè ge : this, this one\n",
      "方式 fāng shì : way, manner, style, mode, pattern, \n",
      "这种 zhè zhǒng : this, this kind of, this sort of, this type of\n",
      "系列 xì liè : series, set\n",
      "过程 guò chéng : course of events, process, \n",
      "抽象 chōu xiàng : abstract, abstraction\n",
      "一个 xià yī ge : the next one\n",
      "我们 wǒ men : we, us, ourselves, our\n",
      "发展 fā zhǎn : development, growth, to develop, to grow, to expand\n",
      "自我 zì wǒ : self-, ego (psychology)\n",
      "作品 zuò pǐn : work (of art), opus, \n",
      "所以 suǒ yǐ : therefore, as a result, so, the reason why\n",
      "中国 Zhōng guó : China\n",
      "线条 xiàn tiáo : line (in drawing, calligraphy etc), the lines or contours of a three-dimensional object (hairstyle, clothing, car etc)\n",
      "这些 zhè xiē : these\n",
      "只有 zhǐ yǒu : only\n",
      "可能 kě néng : might (happen), possible, probable, possibility, probability, maybe, perhaps\n",
      "展览 zhǎn lǎn : to put on display, to exhibit, exhibition, show, \n",
      "传统 chuán tǒng : tradition, traditional, convention, conventional\n",
      "早期 zǎo qī : early period, early phase, early stage\n",
      "当代艺术 None\n",
      "一切 yī qiè : everything, every, all\n",
      "艺术家 yì shù jiā : artist, \n",
      "接近 jiē jìn : to approach, to get close to\n",
      "价值 jià zhí : value, worth, fig. values (ethical, cultural etc)\n",
      "设计 shè jì : plan, design, to design, to plan\n",
      "以及 yǐ jí : as well as, too, and\n",
      "视觉 shì jué : sight, vision, visual\n",
      "创作 chuàng zuò : to create, to produce, to write, creative work, creation, \n",
      "空间 kōng jiān : space, \n",
      "这样 zhè yàng : this kind of, so, this way, like this, such\n"
     ]
    }
   ],
   "source": [
    "tokens = get_words(' '.join(paras) )\n",
    "for x in tt.look_up(tokens):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张帆 绘画 布面 劳作 急就章 自叙 属于 成为 山林 现在 逻辑 危险 视为 奇观 基座 气息 仍然 形式主义 水图 抽象画 一张 书写 丙烯 质感 油画 采薇 符号 缓慢 似乎 高度 引自 僵尸 命题 苏轼 废品 存在 几个 有着 古典 几乎 真的 境界 身边 某个 容易 变化 格子 今格 设想 还是 消失 国际 画面 摹拟 之三 它们 完成 占据 禁锢\n"
     ]
    }
   ],
   "source": [
    "print ' '.join(tt.missing(tokens) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extractors\n",
    "\n",
    "### Sources for vocabulary : \n",
    "\n",
    "1. https://en.wiktionary.org/wiki/\n",
    "1. https://chinese.yabla.com\n",
    "\n",
    "Neither of these are difficult to scrape\n",
    "\n",
    "#### Test texts :\n",
    "\n",
    "1. art.china.cn\n",
    "1. mp.weixin.qq.com\n",
    "\n",
    "Neither of these are difficult to scrape\n",
    "but they use different container classes...see code\n",
    "\n",
    "\n",
    "### Wiki\n",
    "\n",
    "The big problem here is that there are repeated <a></a> tags\n",
    "and the regexp isn't trivial\n",
    "\n",
    "`ur'<a.*?>(.*?)</a></span>.*?<a.*?</a></span>.*?<a.*?>(.*?)</a>\\)(.*?)<' `\n",
    "\n",
    "### Yabla\n",
    "\n",
    "This is a standard data collector :\n",
    "\n",
    "1. should check the current dictionnaries before making a request\n",
    "2. the utf8 has to be encoded for the request string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "def yabla_lookup(word_bag = []):\n",
    "    pdef =  re.compile(ur'class=\"definition\">.*?=\"pinyin\">(.*?)<.*?=\"meaning\">(.*?)<',re.DOTALL)\n",
    "    stuff = {x:'' for x in word_bag} \n",
    "\n",
    "    for word in word_bag:\n",
    "        print word,\n",
    "        qq = urllib2.quote(word.encode('utf8'))\n",
    "        base_url = u'https://chinese.yabla.com/chinese-english-pinyin-dictionary.php?define='\n",
    "        data = urllib2.urlopen(base_url + qq).read()\n",
    "        stuff[word] = pdef.search(data)\n",
    "    return stuff\n",
    "\n",
    "def clean(txt, meaning=False):\n",
    "    if meaning : return txt.split('\\n')[0] + ' '\n",
    "    pinyin, meaning = y.group(1), y.group(2)\n",
    "    meanings = meaning.split('CL:')[0] \n",
    "    #there is a trailing \\n so strip() it \n",
    "    return (pinyin, meaning.strip().replace('\\n',', ') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2, re\n",
    "\n",
    "dp = ur'<a.*?>(.*?)</a></span>.*?<a.*?</a></span>.*?<a.*?>(.*?)</a>\\)(.*?)<'\n",
    "dp = re.compile(dp)\n",
    "\n",
    "base_url = 'https://en.wiktionary.org/wiki/Appendix:Mandarin_Frequency_lists'\n",
    "\n",
    "n = 4\n",
    "data = urllib2.urlopen(base_url + '/%d001-%d000'%(n,n+1)).read()\n",
    "matches = dp.findall(data)\n",
    "\n",
    "for x in matches[:]:\n",
    "    entity, pinyin, meaning = [unicode(w,'utf8') for w in x]\n",
    "    wiki_words[entity = (pinyin, meaning[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "#data = urllib2.urlopen('http://art.china.cn/tongzhi/2018-03/13/content_40249473.htm').read()\n",
    "\n",
    "#data = urllib2.urlopen('http://art.china.cn/ysjt/2017-09/20/content_40022118.htm').read()\n",
    "#data = urllib2.urlopen('http://art.china.cn/haiwai/2016-05/06/content_8753835.htm').read()\n",
    "data = urllib2.urlopen('http://mp.weixin.qq.com/s/FIBpmy2GFPRMvXFNCd8lLg').read()\n",
    "\n",
    "def extract_contents(html,\n",
    "                        div_class='content'):\n",
    "    \n",
    "    '''return all the paragraphs in the html'''\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    payload = soup.find('div', {'class' : div_class})\n",
    "    return [p.text for p in payload.find_all('p')]  \n",
    "\n",
    "class4 = {'art.china.cn': 'content', 'mp.weixin.qq.com' : \"rich_media_content \" }\n",
    "contents2 = extract_contents(data, \n",
    "                             div_class=class4['mp.weixin.qq.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tt.update(new_stuff)\n",
    "tt.dump()\n",
    "mm = wiki_words.missing(top100) \n",
    "print '\\ '.join( tt.missing(mm) )\n",
    "new_stuff = yabla_lookup(tt.missing(mm)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "山林\n",
      "一张\n",
      "布面\n",
      "急就章\n",
      "水图\n",
      "张帆\n",
      "自叙\n",
      "抽象画\n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "for x,y in new_stuff.items():\n",
    "    try:\n",
    "        new_stuff[x] = clean(y)\n",
    "    except:\n",
    "        failed.append(x)\n",
    "        \n",
    "print '\\n'.join(failed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with what is left we are going to have to do some **mechanical turk**\n",
    "\n",
    "Trouble is that google translate uses seriously obfuscated javascript...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = u'''山林\n",
    "采薇\n",
    "引自\n",
    "一张\n",
    "真的\n",
    "布面\n",
    "今格\n",
    "水图\n",
    "自叙\n",
    "抽象画'''\n",
    "\n",
    "pyn = u'''Shānlín\n",
    "cǎi wēi\n",
    "yǐn zì\n",
    "yī zhāng\n",
    "zhēn de\n",
    "bù miàn\n",
    "jīn gé\n",
    "shuǐ tú\n",
    "zìxù\n",
    "chōuxiàng huà'''\n",
    "\n",
    "tgt = '''Mountain forest\n",
    "Petch\n",
    "cited from\n",
    "One sheet\n",
    "Really\n",
    "Cloth surface\n",
    "In this case\n",
    "Water map\n",
    "Self-description\n",
    "Abstract painting'''\n",
    "\n",
    "payload = zip([ x.lower() for x in pyn.split('\\n') ],\n",
    "[ x.lower() for x in tgt.split('\\n') ])\n",
    "for w, dd in zip( src.split('\\n'), payload):\n",
    "    new_stuff[w] = dd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the dictionnary clean !! \n",
    "There is a risk of getting str from the clipboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in new_stuff.keys():\n",
    "    if isinstance(x,str):\n",
    "        del stuff[x]\n",
    "\n",
    "for x in [u'苏摩 苏摩']:\n",
    "    if x in new_stuff:\n",
    "        del new_stuff[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_stuff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1664d6f8fd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_stuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_stuff' is not defined"
     ]
    }
   ],
   "source": [
    "for x,y in new_stuff.items():\n",
    "    print x, '%s %s' %y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_replace(text, adict):\n",
    "    rx = re.compile('|'.join(map(re.escape, adict)))\n",
    "    def one_xlat(match):\n",
    "        return adict[match.group(0)]\n",
    "    return rx.sub(one_xlat, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multiple_replace(content, m2ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 20, 390, 0, 222, 5, 275, 355, 0, 186, 5]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content2 = '\\n'.join(x.text for x in doc.paragraphs \n",
    "                             if x.text and len(ep.findall(x.text) ) < 30 )\n",
    "#print content2\n",
    "\n",
    "[ len(ep.findall(x.text) )for x in doc.paragraphs  if x.text] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.175,\n",
       " 0.0,\n",
       " 0.055865921787709494,\n",
       " 0.31630170316301703,\n",
       " 0.0,\n",
       " 0.2817258883248731,\n",
       " 0.01845018450184502,\n",
       " 0.29411764705882354,\n",
       " 0.281076801266825,\n",
       " 0.0,\n",
       " 0.2957074721780604,\n",
       " 0.18518518518518517]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ len(ep.findall(x.text)) / float(len(x.text)) for x in doc.paragraphs  if x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras = [ x for x in contents2 if len(x)>0 and len(ep.findall(x.lower()))/float(len(x)) <.2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“张帆” 今格空间 展览现场\n",
      "张帆的《急就章》是一组对现在说“不”的作品，这个“不”的核心，在于他认为现在的抽象画依赖劳作量赋予意义，或者把劳作量置换成一种观念，“靠巨大的劳作量和劳作时间来完成一张作品的这种方式属于奇观式的绘画”，“理论上说，这种绘画任何人都可以完成，只需要对一个物体反复进行一种简单机械的操作就可以成就一种奇观”，这些奇观企图掩盖这样一个事实：精神性逐渐丧失，抽象画已沦为平面构成和工业设计的玩物。\n",
      " \n",
      "仔细想一想我们身边的状况，似乎恰如他反对的那样，几乎每天都有大量的抽象作品被生产出来，它们拥有称得上精耕细作的外观和质感，特定的个人符号和图式，即使在后一方面不那么突出，但通过长期的经营，终得以在某个阶段固执地占据了我们的记忆，当那一天到来的时候，这个画家就宣告成立了——这种方法论不止在我们身边生效，也在国际通行；“僵尸形式主义”这个术语的出现，正是对那些“把基于过程的抽象画搞得如此让人难以忍受的”艺术家的明确反讽。[1]\n",
      "张帆，《急就章第六组之三》，布面丙烯，200x200cmx2，2017\n",
      "不过，仅仅说“不”是容易的，也是危险的，危险在于：当你置身于一种对立性的逻辑中，自我有可能随对立面一起缩减。将这种危险阐释得更具体一些：在你锐化社会学或艺术现象学的某些命题的同时，你的思维和表达很容易会被圈禁其中，这是一种反向的禁锢，但仍然是禁锢，它提供了对抗的激情，但并不保证一个主体进行真正的自我建构——幸而，他不只是对现在说“不”，也是在对过去的自己说“不”，并且，他赖以说“不”的基座是我们渴望赎回的传统。\n",
      " \n",
      "对于抽象艺术，张帆曾经抱有某种现代主义式的骄傲，他早期的格子系列耽留于那种经典框架内，以追随巴尼特·纽曼、罗斯科等人的方式，通过垂直的结构和优良的质地，来体现他“对庄重，崇高，含蓄的绘画追求”。设想他一直循沿这种做法，纵然会错过一、两次抽象在中国的热潮，也可以缓慢地占据一席之地，成为重要展览或收藏拼图的一角，但是，当他的认知产生变化之后，他几乎在另启炉灶，这并非缺乏耐心的表现，也不应该被视为一幕针对他人成功的复仇剧，原因只有一个：基座的重置——他想要在中国画传统中发掘抽象的可能。\n",
      " \n",
      "张帆，《覆盖在白色，黑色表面的灰色以及棕色的习作之二》，布面油画，400x250cm，2009\n",
      "《溪山林泉》和《水图》系列展示了他如何摒弃愉悦视觉的装饰感，向古典回溯，而《自叙帖》系列的出现，则表明他放弃了图像性的暗示，更进一步地接近北宋苏轼所倡导的“书法性的表现主义”。[2]简单地说，在最近的七、八年间，他以自我训练的方式缓慢地重演古典艺术史，对此他有过清楚的表述：我曾经说过我在作品中与宋画之间是一种半推半就的关系，我的初衷是消除形式。《溪山林泉》和《水图》这两个系列是我依照我的绘画逻辑发展出来的结果，从早期纵横交错的格子，到只有垂直结构的坚硬质感，再到我彻底消灭了画面中几何意义上的秩序，以一种被几个层次依次覆盖并留白的物理秩序来建立出另一种抽象绘画的结构，通过这几个阶段的发展，当一切直观上带有视觉符号意味的形式的消失，唯一可被感受到的就只有气息，这种气息隐约浮现和弥漫出一种五代北宋的绘画气质，所以我用了《溪山林泉》这个标题来进行代指。由于这个系列的朴素的描绘性的绘画方式还是无法尽情的言志达意，而我希望可以把所有的信息凝聚到一时一刻，把身体状态和情感状态精确的用一瞬间表达出来，所以《水图》开始有了一点点的书写方式存在。到了《采薇》和《自叙帖》，则完全是主动的使用这种书写性的绘画方式了，这个过程与中国绘画发展的逻辑也是相似的。[3]\n",
      "张帆，《溪山林泉》，布面油画，150x260cm，2010\n",
      "张帆，《溪山林泉》，布面油画，150x150cm，2010\n",
      "这个过程慢慢地归结到“气息”（类似气韵说）以及“笔墨就是一切”上来，可谓观念性的复古。当书写性成为他的阶段性命题之后，他早期作品中整饬、华丽、工笔式的描画感和设计性消失了，代之以焦灼、粗放的写意性笔触，这在《采薇》和《自叙帖》中有着明显的体现，如果说在经历变化的整个过程中，成为一幅画的意识仍然盘踞在他的大脑中，《急就章》则是“溢而为书”，[4]要成为一张帖，这个系列的创作过程如题所示，速度极快，一张四米乘两米的大画在短短一个小时之内画完，横贯画面的成排线条摹拟了古代行草的走势，线条虽不具字形，但有着连绵起伏、一气呵成的意味，他的设想就在于线条“相互之间协调的节奏感，细节，质感，情绪，律动等等元素。这些元素都是在书写的过程中瞬间迸发出来的”。\n",
      "张帆，《急就章第七组之一》，布面丙烯，160x200cm，2017\n",
      "张帆，《2015年的自叙帖之三》，布面丙烯，150x180cm，2015\n",
      "在这样的工作方式中，劳作量被驱逐到画面之外，它不再能充当价值交换的堂皇说辞，而是恢复成应有的地位：蜷伏在画室角落里有待清除的成百上千张废品里——它属于日常的“渐修”，而被视为完成的作品则属于某种意义上的“顿悟”和到达。当然，我会试图多理解《急就章》一些，就这些被视为完成的作品而言，它们仍然属于一种高度理想化的摹拟，因为，与废品相比落差固然存在，但说到底它们还是假设了自我的更高境界，而非真的从笔墨、技艺和境界的意义上达到了某个绝对的高度，所以，它们似乎始终透出那么一种顽劣劲儿——并非真的很牢固地占据了古典主义的基座，但无疑像一种令人不安的箭头，冒着形式主义和仿生学的嫌疑，指示出传统中那些接近完美的创造物及其转化的可能。\n",
      " \n",
      "2018年3月\n",
      " \n",
      "[1] 引自NicholasChittenden Morgan《僵尸形式主义，1970—2016》一文，刊载于2016年12月7日Artforum中文网。\n",
      " \n",
      "[2] 引自毕淑珍（MaggieBickford）《墨梅》（Ink Plum）第六章，江苏人民出版社2012年5月版。\n",
      " \n",
      "[3] 引自今格空间对张帆的访谈。\n",
      " \n",
      "[4] 引自苏轼《文与可画墨竹屏风赞》。\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "March, 2018\n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "GINKGO SPACE成立于2014年。通过展览、出版、驻留等多种方式，建立具有广泛影响力的开放平台，GINKGO SPACE积极参与国际当代艺术的发展进程，探索亚洲当代艺术的独特美学价值和文化身份，持续关注中国艺术家的多元创作。\n",
      "需要更多信息，请联系我们\n",
      " +86 10 5762 6135\n",
      "开放时间  10:30-17:30 周二至周六（Tues-Sat）\n",
      "北京市朝阳区酒仙桥路4号院 798艺术区65幢\n"
     ]
    }
   ],
   "source": [
    "txt = '\\n'.join(paras)\n",
    "print txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "观众 guān zhòng : spectators, audience, visitors (to an exhibition etc)\n",
      "装置 zhuāng zhì : to install, installation, equipment, system, unit, device\n",
      "一个 xià yī ge : the next one\n",
      "作品 zuò pǐn : work (of art), opus, \n",
      "空间 kōng jiān : space, \n",
      "展览 zhǎn lǎn : to put on display, to exhibit, exhibition, show, \n",
      "选择 xuǎn zé : to select, to pick, choice, option, alternative\n",
      "艺术家 yì shù jiā : artist, \n",
      "自然 zì rán : nature, natural, naturally\n",
      "思考 sī kǎo : to reflect on, to ponder over\n"
     ]
    }
   ],
   "source": [
    "new_words = get_words(contents2)\n",
    "for x in tt.look_up(new_words)[:10]:\n",
    "    print x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 奥莱 卡斯特 渐近线 能够 决定 无限 怀疑 幻觉 还有 观展 其中 感官 人们 其他 直线 这样 不同 曲线 参与 哪条 愉悦 当代艺术 颜色 文森特 时间 融入 这位 看来 根据 延伸 生于 组成 视觉 应该 所以 只有 可能 不断 相同 展现 比利 才能 对称 固有 拥有 这次 现长 别人 直接 对比 参展者 近于零 冥想 彩色 比如说 觉得 二分之一\n"
     ]
    }
   ],
   "source": [
    "new_stuff = yabla_lookup(tt.missing(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "for x,y in new_stuff.items():\n",
    "    try:\n",
    "        new_stuff[x] = clean(y)\n",
    "    except:\n",
    "        failed.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融入\\ 近于零\\ 还有\\ 这位\\ 看来\\ 感官\\ 文森特\\ 展现\\ 觉得\\ 观展\\ 怀疑\\ 时间\\ 视觉\\ 卡斯特\\ 颜色\\ 所以\\ 能够\\ 根据\\ 可能\\ 冥想\\ 只有\\ 其他\\ 参展者\\ 人们\\ 决定\\ 彩色\\ 不断\\ 参与\\ 其中\\ 二分之一\\ 比如说\\ 比利\\ 延伸\\ 对称\\ 应该\\ 奥莱\\ 哪条\\ 组成\\ 渐近线\\ 直线\\ 拥有\\ 固有\\ 相同\\ 生于\\ 才能\\ 不同\\ 曲线\\ 现长\\ 这次\\ 无限\\ 当代艺术\\ 别人\\ 幻觉\\ 直接\\ 对比\\ 这样\\ 愉悦\n"
     ]
    }
   ],
   "source": [
    "print '\\ '.join(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.update(new_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt.dump()\n",
    "tt = MyWords()\n",
    "tt.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蒋兆和\n",
      "于洋\n",
      "苦茶\n",
      "生民\n",
      "乡关\n",
      "家国\n"
     ]
    }
   ],
   "source": [
    "print '\\n'.join( tt.missing(tags2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = Document('/Users/macbuse/Downloads/ZHU_TRANSLATIONS/holler_CN.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你早期的工作主要是针对农乡科学，直到1994年你一直在从事昆虫研究员的工作，专门从事的研究是昆虫如何通过嗅觉进行彼此沟通。那么是什么时候你开始转向艺术工作，导致你转变的原因是什么？\n",
      "1\n",
      "\n",
      "在早期的艺术作品中，你显示对数学和几何方面浓厚兴趣，大量作品探讨对现实世界分割的方法，在这段时间的创作对后来的空间作品有哪些方面的铺垫？\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "在2006年你创作了一些大型的公共性艺术空间，像《实验场》、《游乐场》、《飞行器》能否介绍一下这三件作品的思路。事实上你在对出现工业革命之后平民体验科学乐趣的方式做了一些有意识的改变，当然我们也会思考这些器材产生的乐趣本身的目的性以及也会从控制论的角度来思考这系列作品，事实上这些作品将人类置于一种封闭的快感过程当中，将主体的经验做有意识的隔离和切分，当然这些器材出现在第一次和第二次工业革命，而并未涉及到微电子时代人类对自身控制的形式，那么你是怎样看待现代人在新的工业机制中所显示的状态？\n"
     ]
    }
   ],
   "source": [
    "for i, pp in enumerate(doc.paragraphs[:6]):\n",
    "    if not pp.text:  print i\n",
    "    print pp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really shitty way to make a webpage :()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_words = MyWords(src_pkl='wiki_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki_words.items())\n",
    "wiki_words.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要 <type 'unicode'> yào demand,request\n",
      "一切 <type 'unicode'> yīqiè det.: everything, every\n",
      "謝謝 <type 'unicode'> xièxiè thank\n",
      "範圍 <type 'unicode'> fànwéi demesne,latitude,shot,compass,extensity,panorama,parameter,boundary,arena,stretch,territory,radius,spectrum,scope,extension,sphere,orbit,circumscription,limits,purview,grasp,extent,region,space,limit,hemisphere,horizon,envelope,bounds,realm,terrain,tether,sphere of influence,range,circuit,domain,precinct,reach,area,length,spread,bailiwick,ambit,con\n",
      "怎麼 <type 'unicode'> zěnme how\n",
      "於是 <type 'unicode'> yūshì conj.: thereupon,hence,consequently,as a result\n",
      "一樣 <type 'unicode'> yīyàng same,equal,similar\n",
      "美國 <type 'unicode'> měiguó House_of_Representatives,the United States of America,US,U.S.A.,bench,Columbia,Yankeeland,U.S.,United States,Democrat,Yankeedom,USA,America,United States of America\n",
      "系列 <type 'unicode'> xìliè succession,set,spectrum,course,train,series\n",
      "所以 <type 'unicode'> suǒyǐ conj.: so,therefore,as a result\n"
     ]
    }
   ],
   "source": [
    "for x,y in wiki_words.items()[:10]:\n",
    "    print x, type(y[0]),'%s %s'%y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
